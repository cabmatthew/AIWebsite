{% load static %}
{% load css_tags %}
<!-- module.html -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>SecureAI</title>
</head>

    <!-- Include the css templates -->
    {% include 'csstemplate.html' %}
<body>
        <meta charset="utf-8">
        <meta content="width=device-width,initial-scale=1" name="viewport">
        <title>SecureAI: Cybersecurity Training in AI</title>
        <meta name="author" content="Mohammed Abuhamad">
        <meta name="description" content="Assistant professor of Computer Science at Loyola University Chicago">
        <link href="/static/assets/img/favicon.ico" rel="icon">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,600,600i,700,700i,900"
              rel="stylesheet">
        <link href="/static/assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
        <link href="/static/assets/vendor/icofont/icofont.min.css" rel="stylesheet">
        <link href="/static/assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
        <link href="/static/assets/vendor/animate.css/animate.min.css" rel="stylesheet">
        <link href="/static/assets/vendor/venobox/venobox.css" rel="stylesheet">
        <link href="/static/assets/vendor/aos/aos.css" rel="stylesheet">
        <link href="/static/assets/css/style.css" rel="stylesheet">

<body>
    <header id="header">
        <div class="container">
            <nav class="nav-menu float-right d-none d-lg-block">
                <ul>
                    <h4>SecureAI</h4>
                    <li class="active">
                        <a href="#header">Home</a>
                    </li>
                    <li>
                        <a href="#about">About Program</a>
                    </li>
                    <li>
                        <a href="#workshops">Workshops</a>
                    </li>
                    <li>
                        <a href="#FAQ">FAQ</a>
                    </li>
                    <li>
                        <a href="#contact">Contact</a>
                    </li>
                    <li>
                        <a href="https://forms.office.com/r/DFYHU5EgTM" target="_blank">Join Program</a>
                    </li>
    
                </ul>
            </nav>
        </div>
    </header>
    <section id="workshops" class="portfolio">
        <div class="container" data-aos="fade-up" data-aos-delay="100">
            <div class="section-title">
                <a href="http://127.0.0.1:8000/program/1">Return to program</a>
                <h3 class="into-sub-title">Workshops</h3>
            </div>
            <div class="row">
                <div class="col-lg-6" data-aos="fade-up">
                    <div class="portfolio_card">
                        <div class="card-title">
                            <!-- <a href="workshop.html"> -->
                            <a href="workshop/1">
                            <h4>Workshop 1: Introduction and Fundamentals</h4>
                            </a>
                        </div>
                        <div class="card-body">
                            <p>
                                <b style="color: #000000; font-weight: bold;">Wednesday, May 1:</b> This workshop introduces participants to the key concepts of AI, cybersecurity, and
                                privacy while highlighting their importance and creating awareness of potential risks
                                and ethical considerations. It is crucial to provide a high-level overview and generate
                                curiosity for further exploration in subsequent workshops. The panel will discuss
                                examples of how different industries use AI and the potential biases and risks
                                associated with it.
                                <br>
                                <br>
                            </p>
                        </div>
                    </div>
                </div>
                <div class="col-lg-6" data-aos="fade-up" data-aos-delay="100">
                    <div class="portfolio_card mb-4 box-shadow">
                        <div class="card-title">
                            <a href="workshop.html">
                            <h4>Workshop 2: AI and Threat Models</h4>
                        </a>
                        </div>
                        <div class="card-body">
                            <p>
                                <b style="color: #000000; font-weight: bold;">Wednesday, May 15:</b> This workshop highlights the threat landscape in AI systems and the concept of
                                adversarial attacks. It builds on the previous workshop and presents real-world examples
                                to emphasize the importance of addressing these threats.
                                The key concepts covered include threat models, adversarial attacks, model robustness,
                                and defenses.

                                <br>
                                <br>
                            </p>
                        </div>
                    </div>
                </div>
                <div class="col-lg-6" data-aos="fade-up" data-aos-delay="200">
                    <div class="portfolio_card mb-4 box-shadow">
                        <div class="card-title">
                            <a href="workshop.html">
                            <h4>Workshop 3: Adversarial Attacks</h4>
                        </a>
                        </div>
                        <div class="card-body">
                            <p>
                                <b style="color: #000000; font-weight: bold;">Wednesday, May 29:</b> This workshop provides a broad understanding of adversarial attacks in AI by focusing on
                                the different types of attack, their methods, and their potential impact on AI systems.
                                The workshop delves into different types of adversarial attacks, such as evasion,
                                poisoning, and model inversion under various threat models (e.g., white- and black-box
                                settings). Moreover, it addresses aspects such as transferability, single-class and
                                targeted attacks.
                                <br>
                                <br>
                            </p>
                        </div>
                    </div>
                </div>

                <div class="col-lg-6" data-aos="fade-up" data-aos-delay="300">
                    <div class="portfolio_card mb-4 box-shadow">
                        <div class="card-title">
                            <a href="workshop.html">
                            <h4>Workshop 4: Robustness and Resilience</h4>
                        </a>
                        </div>
                        <div class="card-body">
                            <p>
                                <b style="color: #000000; font-weight: bold;">Wednesday, June 12:</b> This workshop provides a comprehensive understanding of the key concepts related to
                                robustness and resilience in AI models. These concepts include general and adversarial
                                robustness (i.e., the ability of the model to perform consistently and accurately in the
                                presence of uncertainties and perturbations), domain adaptation and transfer learning,
                                model generalization, and fault tolerance. These concepts help participants understand
                                the challenges facing AI systems and learn strategies to improve their stability,
                                reliability, and performance.
                                <br>
                                <br>
                            </p>
                        </div>
                    </div>
                </div>
                <div class="col-lg-6" data-aos="fade-up" data-aos-delay="400">
                    <div class="portfolio_card mb-4 box-shadow">
                        <div class="card-title">
                            <a href="workshop.html">
                            <h4>Workshop 5: AI and Privacy: Differential Privacy and Federated Learning</h4>
                        </a>
                        </div>
                        <div class="card-body">
                            <p>
                                <b style="color: #000000; font-weight: bold;">Wednesday, June 26:</b> This workshop introduces key concepts of privacy in the context of AI and explores
                                privacy-preserving methods around differential privacy and federated learning.
                                The workshop discusses challenges and methods to preserve privacy while leveraging
                                sensitive data for AI model training. This includes understanding potential privacy
                                risks caused by either unintended memorization of sensitive data or adversarial means
                                (e.g., model inversion and inference attacks). The discussion also includes describing
                                the privacy budget and trade-offs between privacy and utility.
                                The panel will discuss the benefits, challenges, and potential risks in federated
                                learning and decentralized data settings.
                                <br>
                                <br>
                            </p>
                        </div>
                    </div>
                </div>

                <div class="col-lg-6" data-aos="fade-up" data-aos-delay="500">
                    <div class="portfolio_card mb-4 box-shadow">
                        <div class="card-title">
                            <a href="workshop.html">
                            <h4>Workshop 6: Ethics in AI: Bias and Fairness</h4>
                        </a>
                        </div>
                        <div class="card-body">
                            <p>
                                <b style="color: #000000; font-weight: bold;">Wednesday, July 10:</b> The goal of this workshop is to explore ethical considerations in AI, specifically
                                focusing on the concepts of bias and fairness. Participants will gain an understanding
                                of the challenges associated with bias in AI systems and the importance of promoting
                                fairness and mitigating discrimination.
                                The panel discussion will focus on the responsibility of AI practitioners to address
                                bias (i.e., different types of biases such as algorithmic bias, data bias, and societal
                                bias) and to prompt fairness in AI systems.
                                Considering real-world examples, e.g., a biased hiring system, studying the impact of
                                bias and approaches to mitigate bias, including data pre-processing techniques,
                                algorithmic adjustments, and fairness-aware model training.
                                <br>
                                <br>
                            </p>
                        </div>
                    </div>
                </div>

                <div class="col-lg-6" data-aos="fade-up" data-aos-delay="500">
                    <div class="portfolio_card mb-4 box-shadow">
                        <div class="card-title">
                            <a href="workshop.html">
                            <h4>Workshop 7: Trust in AI: Transparency, Explainability, and Interpretability</h4>
                        </a>
                        </div>
                        <div class="card-body">
                            <p>
                                <b style="color: #000000; font-weight: bold;">Wednesday, July 24:</b> This workshop explores the importance of trust in AI systems and introduces participants
                                to the concepts of transparency, explainability, and interpretability. Participants will
                                understand the role of these concepts in building trust, ensuring accountability, and
                                addressing the black-box nature of AI models.
                                The key concepts addressed in this workshop are, 1) trust in AI and its significance in
                                fostering user and societal acceptance, 2) explainability and interpretability in AI and
                                the ability to understand and trace the decision-making process of AI models, and
                                3) techniques for explainability and interoperability including examples for post-hoc
                                techniques and inherently interpretable models.
                                <br>
                                <br>
                            </p>
                        </div>
                    </div>
                </div>

                <div class="col-lg-6" data-aos="fade-up" data-aos-delay="500">
                    <div class="portfolio_card mb-4 box-shadow">
                        <div class="card-title">
                            <a href="workshop.html">
                            <h4>Workshop 8: AI Development and Security</h4>
                        </a>
                        </div>
                        <div class="card-body">
                            <p>
                                <b style="color: #000000; font-weight: bold;">Wednesday, August 7:</b> This workshop introduces the concepts of DevOps (Development and Operations) and MLOps
                                (Machine Learning Operations) in the context of AI security. Participants will
                                understand the importance of integrating security practices into the AI development
                                lifecycle and learn how DevOps and MLOps can enhance the security and reliability of AI
                                systems.
                                The key concepts covered in this workshop are:
                                1) DevOps practices in the context of AI development to improve collaboration,
                                efficiency, and quality,
                                2) Integration of security into the DevOps workflow,
                                3) MLOps practices and tools to manage the lifecycle of machine learning models,
                                including development, deployment, and monitoring,
                                4) Security considerations during the model development phase,
                                5) Regulatory requirements and industry standards, such as GDPR, HIPAA, ISO 27001, and
                                NIST Cybersecurity Framework.
                                <br>
                                <br>
                            </p>
                        </div>
                    </div>
                </div>

                <div class="col-lg-6" data-aos="fade-up" data-aos-delay="500">
                    <div class="portfolio_card mb-4 box-shadow">
                        <div class="card-title">
                            <a href="workshop.html">
                            <h4>Workshop 9: AI and Data Governance: Regulations and Standards</h4>
                        </a>
                        </div>
                        <div class="card-body">
                            <p>
                                <b style="color: #000000; font-weight: bold;">Wednesday, August 21:</b> This workshop introduces key regulations and standards related to AI and data governance.
                                Participants will understand the legal and ethical considerations involved in AI
                                development and deployment and the importance of compliance with regulations and
                                adherence to industry standards.
                                The concepts covered are:
                                1) Introduction to data governance in the context of AI, including data collection,
                                storage, processing, and sharing, and the importance of ensuring the privacy, security,
                                and ethical use of data in AI systems.
                                2) Introduction to legal (e.g., GDPR, CCPA, and the EU AI Act, and ethical frameworks
                                around AI systems.
                                3) Data privacy and protection principles, e.g., consent, purpose limitation, and the
                                right to erasure, and methods for data protection, e.g., anonymization,
                                pseudonymization, and encryption.
                                4) Responsible AI and impact assessment.
                                <br>
                                <br>
                            </p>
                        </div>
                    </div>
                </div>

                <div class="col-lg-6" data-aos="fade-up" data-aos-delay="500">
                    <div class="portfolio_card mb-4 box-shadow">
                        <div class="card-title">
                            <a href="workshop.html">
                            <h4>Workshop 10: Secure Deployment and Operation of AI Systems</h4>
                        </a>
                        </div>
                        <div class="card-body">
                            <p>
                                <b style="color: #000000; font-weight: bold;">Wednesday, September 4:</b> This workshop highlights the importance of secure deployment and operation of AI systems
                                and introduces key concepts and best practices to ensure the security and resilience of
                                AI systems throughout their lifecycle.
                                The emphasis in this workshop is on the secure deployment of AI models and the
                                importance of collaboration between development, operations, and security teams during
                                the operational stage of the system lifecycle to maintain system integrity.

                                <br>
                                <br>
                            </p>
                        </div>
                    </div>
                </div>


                <div class="col-lg-6" data-aos="fade-up" data-aos-delay="500">
                    <div class="portfolio_card mb-4 box-shadow">
                        <div class="card-title">
                            <a href="workshop.html">
                            <h4>Workshop 11: Case Study (I)</h4>
                        </a>
                        </div>
                        <div class="card-body">
                            <p>
                                <b style="color: #000000; font-weight: bold;">Wednesday, September 18:</b> This workshop analyzes real-world cases and outline practices and challenges with respect
                                to cybersecurity and privacy in AI systems.
                                <br>
                                <br>
                            </p>
                        </div>
                    </div>
                </div>


                <div class="col-lg-6" data-aos="fade-up" data-aos-delay="500">
                    <div class="portfolio_card mb-4 box-shadow">
                        <div class="card-title">
                            <a href="workshop.html">
                            <h4>Workshop 12: Case Study (II)</h4>
                        </a>
                        </div>
                        <div class="card-body">
                            <p>
                                <b style="color: #000000; font-weight: bold;">Wednesday, October 2:</b> This workshop analyzes real-world cases and outline practices and challenges with respect
                                to cybersecurity and privacy in AI systems.
                                <br>
                                <br>
                            </p>
                        </div>
                    </div>
                </div>


            </div>
        </div>
    </section>
    
    <footer id="footer" class="footer bg-overlay">
        <div class="footer-main">
            <div class="container">
                <div class="row justify-content-between">
                    <div class="col-lg-6 col-md-6 footer-widget footer-about">
                        <h3 class="widget-title">Loyola Center for Cybersecurity</h3>
                        <p>Loyola University Chicago is designated by the NSA/DHS as a Center of Academic Excellence in Cyber Defence.
                           The cybersecurity program offered by the university is recognized by the National Security Agency and the Department of Homeland Security.</p>
                        <ul style="list-style-type:none;padding-left:0">
                            <li>306
                                Doyle Center, Lake Shore Campus</li>
                            <li>1052 W Loyola Ave. Chicago, IL 60626</li>
                        </ul>
    
                    </div>
    
                    <div class="col-lg-4 col-md-6 mt-5 mt-lg-0 footer-widget">
                        <h3 class="widget-title">Links</h3>
                        <ul class="list-arrow">
                            <li>
                                <a href="https://www.luc.edu/" target="_blank">Loyola University Chicago</a>
                            </li>
                            <li>
                                <a href="https://www.luc.edu/cs/index.shtml" target="_blank">Computer Science Department</a>
                            </li>
                            <li>
                                <a href="https://newsroom.cs.luc.edu/" target="_blank">Computer Science Newsroom</a>
                            </li>
                            <li>
                                <a href="https://www.luc.edu/cs/loyolacenterforcybersecurity/" target="_blank">Loyola Center
                                                                                                               for
                                                                                                               Cybersecurity</a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </footer>
    <a href="#" class="back-to-top">
        <i class="icofont-simple-up"></i>
    </a>


    <script src="/static/assets/vendor/jquery/jquery.min.js"></script>
    <script src="/static/assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
    <script src="/static/assets/vendor/jquery.easing/jquery.easing.min.js"></script>
    <script src="/static/assets/vendor/jquery-sticky/jquery.sticky.js"></script>
    <script src="/static/assets/vendor/venobox/venobox.min.js"></script>
    <script src="/static/assets/vendor/waypoints/jquery.waypoints.min.js"></script>
    <script src="/static/assets/vendor/counterup/counterup.min.js"></script>
    <script src="/static/assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
    <script src="/static/assets/vendor/aos/aos.js"></script>
    <script src="/static/assets/js/main.js"></script>

</body>
</html>
